{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/Giang/Applications/anaconda/envs/UdacityNanoCar/lib/python3.5/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-df394921c170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, shutil\n",
    "import cv2\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import facenet\n",
    "import align.detect_face\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./kyc/lib/python3.6/site-packages (4.1.1.26)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in ./kyc/lib/python3.6/site-packages (from opencv-python) (1.14.1)\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-30de0834b92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "name = \"Phap\"\n",
    "data_path = \"/home/g/Desktop/3KYC/Facenet/Dataset/{}/\".format(name)\n",
    "\n",
    "# delete files\n",
    "def remove_processed():\n",
    "    folder = '/home/g/Desktop/3KYC/Facenet/Dataset/{}/processed/'.format(name)\n",
    "    # shutil.rmtree(folder, ignore_errors=False, onerror=None)\n",
    "    for file in os.listdir(folder):\n",
    "        try:\n",
    "            shutil.rmtree(folder+file, ignore_errors=False, onerror=None)\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        os.remove(folder+\"revision_info.txt\")\n",
    "    except:\n",
    "        pass\n",
    "    print(\"delete all in processed folder!\")\n",
    "\n",
    "# change file name \n",
    "def change_names():\n",
    "    folder = '/home/g/Desktop/3KYC/Facenet/Dataset/{}/row/'.format(name)\n",
    "    print(\"len row folder: \", len(os.listdir(folder)))\n",
    "    for file in os.listdir(folder):\n",
    "        path = folder + file\n",
    "        for num,image in enumerate(os.listdir(path)):\n",
    "            num+=1\n",
    "            src=path+'/'+image\n",
    "            print(src)\n",
    "\n",
    "            dst=path+'/'+str(num)+\".jpg\"\n",
    "            print(dst)\n",
    "\n",
    "            os.rename(src,dst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# find bounding boxes\n",
    "def bounding_boxes(data_path=data_path):\n",
    "    if not os.path.exists( data_path+'processed' ):\n",
    "        os.makedirs( data_path+'processed' )\n",
    "    # Store some git revision info in a text file in the log directory\n",
    "    src_path = os.path.abspath('')\n",
    "    facenet.store_revision_info(src_path, data_path+'processed', 'xx')\n",
    "    print(\"number of classes in DB: \", len(facenet.get_dataset(data_path+'row')))\n",
    "\n",
    "    print('Creating networks and loading parameters')\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "\n",
    "    # Add a random key to the filename to allow alignment using multiple processes\n",
    "    random_key = np.random.randint(0, high=99999)\n",
    "    bounding_boxes_filename = os.path.join(data_path, 'bounding_boxes_%05d.txt' % random_key)\n",
    "    return [bounding_boxes_filename, pnet, rnet, onet]\n",
    "\n",
    "bounding_boxes_filename, pnet, rnet, onet = bounding_boxes(data_path)\n",
    "\n",
    "# count all files in row folder\n",
    "def count_files(data_path=data_path):\n",
    "    num_image = 0\n",
    "    for each_fol in os.listdir(data_path+'row'):\n",
    "        for each in os.listdir(data_path+'row/'+each_fol):\n",
    "            num_image +=1\n",
    "    return num_image\n",
    "\n",
    "\n",
    "# get image and save to \n",
    "def feature_extraction(minsize = 20, \n",
    "                       threshold = [ 0.6, 0.7, 0.7 ], \n",
    "                       factor = 0.709, \n",
    "                       bounding_boxes_filename=bounding_boxes_filename,\n",
    "                       pnet = pnet,\n",
    "                       rnet = rnet,\n",
    "                       onet = onet):\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    dataset = facenet.get_dataset(data_path+'row')\n",
    "    \n",
    "    num_files = count_files()\n",
    "    count = 0\n",
    "    with open(bounding_boxes_filename, \"w\") as text_file:\n",
    "        nrof_images_total = 0\n",
    "        nrof_successfully_aligned = 0\n",
    "        if '--random_order':\n",
    "            random.shuffle(dataset)\n",
    "        \n",
    "        for cls in dataset:\n",
    "            output_class_dir = os.path.join(data_path+'processed', cls.name)\n",
    "            if not os.path.exists(output_class_dir):\n",
    "                os.makedirs(output_class_dir)\n",
    "                if '--random_order':\n",
    "                    random.shuffle(cls.image_paths)\n",
    "\n",
    "            for image_path in cls.image_paths:\n",
    "                nrof_images_total += 1\n",
    "                filename = os.path.splitext(os.path.split(image_path)[1])[0]\n",
    "                output_filename = os.path.join(output_class_dir, filename+'.png')\n",
    "                print(image_path)\n",
    "\n",
    "                if not os.path.exists(output_filename):\n",
    "                    try:\n",
    "                        img = cv2.imread(image_path)\n",
    "                    except (IOError, ValueError, IndexError) as e:\n",
    "                        errorMessage = '{}: {}'.format(image_path, e)\n",
    "                        print(errorMessage)\n",
    "                    else:\n",
    "                        if img.ndim<2:\n",
    "                            print('Unable to align \"%s\"' % image_path)\n",
    "                            text_file.write('%s\\n' % (output_filename))\n",
    "                            continue\n",
    "                        if img.ndim == 2:\n",
    "                            img = facenet.to_rgb(img)\n",
    "                        img = img[:,:,0:3]\n",
    "\n",
    "                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "                        nrof_faces = bounding_boxes.shape[0]\n",
    "\n",
    "                        if nrof_faces>0:\n",
    "                            det = bounding_boxes[:,0:4]\n",
    "                            det_arr = []\n",
    "                            img_size = np.asarray(img.shape)[0:2]\n",
    "\n",
    "                            if nrof_faces>1:\n",
    "                                if False:\n",
    "                                    for i in range(nrof_faces):\n",
    "                                        det_arr.append(np.squeeze(det[i]))\n",
    "                                else:\n",
    "                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n",
    "                                    img_center = img_size / 2\n",
    "                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n",
    "                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n",
    "                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n",
    "                                    det_arr.append(det[index,:])\n",
    "                            else:\n",
    "                                det_arr.append(np.squeeze(det))\n",
    "\n",
    "                            margin = 32\n",
    "                            image_size = 160\n",
    "\n",
    "                            for i, det in enumerate(det_arr):\n",
    "                                det = np.squeeze(det)\n",
    "                                bb = np.zeros(4, dtype=np.int32)\n",
    "                                bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "                                bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "                                bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n",
    "                                bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n",
    "                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "                                scaled = cv2.resize(cropped, (image_size, image_size), cv2.INTER_LINEAR)\n",
    "                                nrof_successfully_aligned += 1\n",
    "                                filename_base, file_extension = os.path.splitext(output_filename)\n",
    "                                if False:\n",
    "                                    output_filename_n = \"{}_{}{}\".format(filename_base, i, file_extension)\n",
    "                                else:\n",
    "                                    output_filename_n = \"{}{}\".format(filename_base, file_extension)\n",
    "                                cv2.imwrite(output_filename_n, scaled)\n",
    "                                count += 1\n",
    "\n",
    "                                # clear_output()\n",
    "                                os.system('cls' if os.name == 'nt' else 'clear')\n",
    "\n",
    "                                print(\"Finish: \", str(float(count/num_files*100)).split(\".\")[0]+\".\"+str(count/num_files*100).split(\".\")[1][:2], \" %\")\n",
    "                                \n",
    "                                text_file.write('%s %d %d %d %d\\n' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n",
    "                        else:\n",
    "                            print('Unable to align \"%s\"' % image_path)\n",
    "                            text_file.write('%s\\n' % (output_filename))\n",
    "                        \n",
    "                \n",
    "\n",
    "    print('Total number of images: %d' % nrof_images_total)\n",
    "    print('Number of successfully aligned images: %d' % nrof_successfully_aligned)\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print('Time: ', stop - start)  \n",
    "   \n",
    "def training(data_path=data_path):\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            dataset = facenet.get_dataset(data_path+'processed')\n",
    "\n",
    "            # Check that there are at least one training image per class\n",
    "#             for class_ in dataset:\n",
    "#                 assert(len(class_.image_paths)>0, 'There must be at least one image for each class in the dataset')            \n",
    "\n",
    "            paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "\n",
    "            print('Number of classes: %d' % len(dataset))\n",
    "            print('Number of images: %d' % len(paths))\n",
    "\n",
    "            # Load the model\n",
    "            print('Loading feature extraction model')\n",
    "            facenet.load_model('../Models/facenet/20180402-114759.pb')\n",
    "\n",
    "            print(\"-- get I/O of tensors\")\n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "            # Run forward pass to calculate embeddings\n",
    "            print('Calculating features for images')\n",
    "            nrof_images = len(paths)\n",
    "            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / 1000))\n",
    "            emb_array = np.zeros((nrof_images, embedding_size))\n",
    "            for i in range(nrof_batches_per_epoch):\n",
    "                start_index = i*1000\n",
    "                end_index = min((i+1)*1000, nrof_images)\n",
    "                paths_batch = paths[start_index:end_index]\n",
    "                images = facenet.load_data(paths_batch, False, False, 160)\n",
    "                feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "\n",
    "            classifier_filename_exp = \"../Dataset/{a}/model/{b}.pkl\".format(a=name, b=name)\n",
    "\n",
    "            print('Training classifier')\n",
    "            model = SVC(kernel='linear', probability=True)\n",
    "            model.fit(emb_array, labels)\n",
    "\n",
    "            # Create a list of class names\n",
    "            class_names = [ cls.name.replace('_', ' ') for cls in dataset]\n",
    "\n",
    "            # Saving classifier model\n",
    "            with open(classifier_filename_exp, 'wb') as outfile:\n",
    "                pickle.dump((model, class_names), outfile)\n",
    "            print('Saved classifier model to file \"%s\"' % classifier_filename_exp)\n",
    "            stop = timeit.default_timer()\n",
    "            time = str(float(stop - start)).split(\".\")\n",
    "            print('Time: '+time[0]+\".\"+time[1][:2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def recognition( MINSIZE = 20,\n",
    "                    THRESHOLD = [0.6, 0.7, 0.7],\n",
    "                    FACTOR = 0.709,\n",
    "                    IMAGE_SIZE = 182,\n",
    "                    INPUT_IMAGE_SIZE = 160):\n",
    "\n",
    "    print(\"\\n__Start recognition__\\n\")\n",
    "    # Load The Custom Classifier\n",
    "    with open(\"../Dataset/{a}/model/{b}.pkl\".format(a=name, b=name), 'rb') as file:\n",
    "        model, class_names = pickle.load(file)\n",
    "        print(\"path: \" + \"../Dataset/{a}/model/{b}.pkl\".format(a=name, b=name))\n",
    "        print(\"model:    \", model)\n",
    "        print(\"class_names:     \", class_names)\n",
    "    print(\"Custom Classifier, Successfully loaded\")\n",
    "\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        \n",
    "        with sess.as_default():\n",
    "            \n",
    "            # Load the model\n",
    "            print('Loading feature extraction model')\n",
    "            facenet.load_model('../Models/facenet/20180402-114759.pb')\n",
    "            # facenet.load_model(\"20180402-114759.pb\")\n",
    "            \n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, \"align\")\n",
    "            \n",
    "            people_detected = set()\n",
    "            person_detected = collections.Counter()\n",
    "            \n",
    "            image_path = \"../Dataset/{a}/ID_CARD/{b}.jpg\".format(a=name, b=name)\n",
    "            \n",
    "            print(\"imge path: \", image_path)\n",
    "            frame = mpimg.imread(image_path)\n",
    "            # frame = cv2.rotate(frame,rotateCode = 2)\n",
    "            \n",
    "            bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\n",
    "            faces_found = bounding_boxes.shape[0]\n",
    "\n",
    "            det = bounding_boxes[:, 0:4]\n",
    "            bb = np.zeros((faces_found, 4), dtype=np.int32)\n",
    "            for i in range(faces_found):\n",
    "                bb[i][0] = det[i][0]\n",
    "                bb[i][1] = det[i][1]\n",
    "                bb[i][2] = det[i][2]\n",
    "                bb[i][3] = det[i][3]\n",
    "\n",
    "                cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\n",
    "                scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "                \n",
    "                scaled = facenet.prewhiten(scaled)\n",
    "                scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\n",
    "                feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n",
    "                emb_array = sess.run(embeddings, feed_dict=feed_dict)\n",
    "                predictions = model.predict_proba(emb_array)\n",
    "                best_class_indices = np.argmax(predictions, axis=1)\n",
    "                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "                best_name = class_names[best_class_indices[0]]\n",
    "\n",
    "                print(\"\\n\\nResult: \\n==================================================\")\n",
    "                print(\"Name: {}, Probability: {}\".format(best_name, best_class_probabilities))\n",
    "                cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (255, 255, 0), 2)\n",
    "                text_x = bb[i][0]\n",
    "                text_y = bb[i][3] + 20\n",
    "                print(\"--\", text_x, \"--\", text_y)\n",
    "                cv2.putText(frame, best_name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 255), thickness=1, lineType=2)\n",
    "                cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y+17), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 255, 255), thickness=1, lineType=2)\n",
    "                \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(\"123.jpg\",frame)\n",
    "            # cv2.imwrite(0)\n",
    "            # print(chr(27) + \"[2J\")\n",
    "            # os.system('cls' if os.name == 'nt' else 'clear')\n",
    "            # clear()\n",
    "\n",
    "\n",
    "\n",
    "pretrain = False\n",
    "\n",
    "if pretrain:\n",
    "    remove_processed()\n",
    "\n",
    "if pretrain:\n",
    "    feature_extraction()\n",
    "    training()\n",
    "recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
